{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34f15ee-8477-4490-813d-740e563338d0",
   "metadata": {},
   "source": [
    "# Summer School: Digitale Methoden der Zeitungsanalyse\n",
    "\n",
    "## Teil 3: Analysieren und Visualisieren der Texte der Alto-Dateien: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc1ec4-8c3f-44be-86aa-be7fb8ad3271",
   "metadata": {},
   "source": [
    "Um die Arbeitsumgebung für die folgenden Schritte passend einzurichten, sollten zunächst die benötigten Python-Biblitoheken importiert werden.\n",
    "\n",
    "- `pandas`: Bibliothek zur Datenanalyse.\n",
    "- `string`: Funktionen zur Bearbeitung von Zeichenketten\n",
    "- `nltk` (Natural Language Toolkit): zur Verarbeitung natürlicher Sprache.\n",
    "- `nltk.corpus`: Liste häufiger Wörter, die bei der Textanalyse oft ignoriert werden sollten\n",
    "- `collections`: Zum Speichern von Wörtern, Wörterbüchern und zum Zählen von Elementen.\n",
    "- `matplotlib` : Zum erstellen von Visualisierungen\n",
    "- `numpy` : Bibliothek für wissenschaftliches Rechnen, Datenanalysen und numerische Berechnungen\n",
    "- `WorldCloud`: Bibliothek zur Erstellung von WordClouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207abcf4-de11-42ce-b351-8afc023ae0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4866325-3584-41a0-a4a2-54cbfd49070a",
   "metadata": {},
   "source": [
    "#### Laden der zuvor gespeicherten Texte: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b2fdd-e6b7-4d86-be74-99607019aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"otra_alemania_content.csv\", encoding = \"UTF-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3593104-b2ad-475c-9884-1d411835782f",
   "metadata": {},
   "source": [
    "## Häufigkeitsanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c228d1-cce5-4f7c-b83b-94f7cf501b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Häufigkeitsanalyse der häufigsten Wörter\n",
    "# Textinhalte aus DataFrame sammeln\n",
    "content = df['text'].tolist()\n",
    "content = [text.lower() for text in content]  # Kleinbuchstaben zur Vereinheitlichung\n",
    "print(content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446f729-b90f-4047-ad92-f50362738136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen von Satzzeichen und Tokenisierung\n",
    "listofthings = []\n",
    "for entry in content:\n",
    "    for c in string.punctuation:\n",
    "        entry = entry.replace(c, \" \")\n",
    "    words = entry.split()\n",
    "    listofthings.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cde48-dcb4-478f-bc38-a4f91ee9626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listofthings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec87a1-e99b-4ec4-809e-c28a7daa4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen von Zahlen (bspw. Seitenzahlen, andere Zahlen)\n",
    "words = [word for word in listofthings if not word.isdecimal()]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9f94e-79f2-4bd9-8327-c2571249bc6c",
   "metadata": {},
   "source": [
    "#### Entfernen von Stopwörtern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b28a6-6900-4885-800e-6db6e69da691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der zu entfernenden Stopwörter\n",
    "nltk.download('stopwords')\n",
    "stopger = stopwords.words('german')\n",
    "\n",
    "# Hinzufügen weiterer Stopwörter\n",
    "newStopwords = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'vgl', '\\x97', '•', '■', 'v',\n",
    "                'beim', 'de','—','ge','la','be','en','que','el','ten','ver','gen','sei','nen','del','nen', 'se','schen','un','land','te','ei','aires',\n",
    "                'las', 'los', '«']\n",
    "\n",
    "#Erweitern der heruntergeladenen Stopwörter mit den selbst definierten \"newStopwords\":\n",
    "stopger.extend(newStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbfc94-e8e0-4d6f-955d-4655232b8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3bb1c-44f6-4975-a130-2aaa6648ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen der Stopwörter aus der Gesamtwortliste: \n",
    "tokens_without_sw = [word for word in words if word not in stopger]\n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf5b38-8c7f-4dda-b6cb-9823afc3cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zählen der Häufigkeit der verbleibenden Wörter\n",
    "counts = Counter(tokens_without_sw)\n",
    "\n",
    "# Top 20 häufigste Wörter ausgeben\n",
    "top_20_words = counts.most_common(20)\n",
    "top_150_words = counts.most_common(150)\n",
    "print(top_20_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a50b4-9d72-4c56-bb90-5d6d96751d59",
   "metadata": {},
   "source": [
    "## Visualisierungen erstellen\n",
    "\n",
    "#### 1. Kreisdiagramm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbff16c-4557-4519-8503-fe449ad838b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen eines Kreisdiagramms\n",
    "def create_circle(word_count):\n",
    "    labels = [word[0] for word in word_count]\n",
    "    sizes = [word[1] for word in word_count]\n",
    "    colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "    plt.axis('equal')  # Kreisdiagramm rund machen\n",
    "    plt.title('Top 20 häufigste Wörter')\n",
    "    plt.show()\n",
    "\n",
    "# Kreisdiagramm erstellen\n",
    "create_circle(top_20_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d4d29-add3-4551-8763-140c3c13fd57",
   "metadata": {},
   "source": [
    "#### 2. Balkendiagramm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c4840-10b3-48b1-8ef9-3c5bec6f6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen eines Balkendiagramms\n",
    "def create_bar_chart(word_count):\n",
    "    labels = [word[0] for word in word_count]\n",
    "    sizes = [word[1] for word in word_count]\n",
    "    \n",
    "    x = np.arange(len(labels))  # Die Label-Positionen\n",
    "    width = 0.75  # Die Breite der Balken\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    rects = ax.bar(x, sizes, width)\n",
    "\n",
    "    # Labels hinzufügen, etc.\n",
    "    ax.set_ylabel('Häufigkeit')\n",
    "    ax.set_title('Top 20 häufigste Wörter')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    \n",
    "    # Balken beschriften\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 Punkte vertikal versetzt\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    return fig, ax\n",
    "    #plt.show()\n",
    "\n",
    "# Balkendiagramm erstellen\n",
    "fig, ax = create_bar_chart(top_20_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df049bae-50d0-4227-90c4-06afe391f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramm als Bild speichern\n",
    "fig.savefig('plot.jpg', format='jpg', dpi=300)  # Als JPG speichern\n",
    "# fig.savefig('plot.png', format='png', dpi=300)  # Als PNG speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d690a32-5809-4f22-bee6-011f399c02ac",
   "metadata": {},
   "source": [
    "#### 3. Wordcloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73283d28-2568-4919-8157-d71c052e993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen einer Wörterbuch-Datenstruktur für die WordCloud\n",
    "word_freq_dict = dict(top_150_words)\n",
    "\n",
    "# Erstellen und Anzeigen der WordCloud\n",
    "wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')  # Achsen ausblenden\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74813cb6-54a5-4b4e-8d63-d7aed8a8d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.to_file('wordcloud.png')  # Speichern als PNG-Datei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69cd4ed-d60c-4474-a0c0-9692852ac43f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Frequenz eines Wortes pro Jahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0235f-af46-409b-acfb-27b3559b7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(content): \n",
    "    \n",
    "    wordlist = []\n",
    "    for word in content.split():\n",
    "        for char in string.punctuation:\n",
    "            word = word.strip(char)\n",
    "        wordlist.append(word) \n",
    "\n",
    "    words = [word for word in wordlist if not word.isdecimal()]\n",
    "    tokens_without_sw = [word for word in words if word not in stopger]\n",
    "\n",
    "    return tokens_without_sw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758cc9d-c326-43c2-a1c2-66ae41d7345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['filename'].str[:4]\n",
    "df['token'] = df['text'].apply(tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795a574-ff84-4245-802e-ce7726f94ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting(tokens): \n",
    "    counts = Counter(tokens)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4427f2f-53a7-4470-b624-7a31cef5df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['counts'] = df['token'].apply(counting)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fb8ac-ed9e-4264-8351-dae93e84fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Wort, dessen Häufigkeit wir analysieren wollen\n",
    "word_to_analyze = 'Amerika'\n",
    "\n",
    "# Häufigkeit des Wortes pro Jahr aggregieren\n",
    "word_counts = df[['year', 'counts']].copy()\n",
    "word_counts['count'] = word_counts['counts'].apply(lambda x: x.get(word_to_analyze, 0))\n",
    "word_counts = word_counts.groupby('year')['count'].sum().reset_index()\n",
    "\n",
    "# Liniendiagramm erstellen\n",
    "fig = px.line(word_counts, x='year', y='count', title=f'Häufigkeit des Wortes \"{word_to_analyze}\" pro Jahr', height=550)\n",
    "fig.update_layout(xaxis_title='Jahr', yaxis_title='Häufigkeit')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee32a60-5fdf-49e3-be7b-91193b55fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Einträge pro Jahr zählen\n",
    "entry_counts = df.groupby('year').size().reset_index(name='entry_count')\n",
    "\n",
    "# Liniendiagramm erstellen\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(go.Scatter(x=data['year'], y=data['count'], mode='lines', name=f'Häufigkeit des Wortes \"{word_to_analyze}\"'))\n",
    "fig2.add_trace(go.Scatter(x=data['year'], y=data['entry_count'], mode='lines', name='Anzahl der Einträge'))\n",
    "\n",
    "fig2.update_layout(\n",
    "    title=f'Häufigkeit des Wortes \"{word_to_analyze}\" und Anzahl der Einträge pro Jahr',\n",
    "    xaxis_title='Jahr',\n",
    "    yaxis_title='Werte',\n",
    "    height=550\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1836314-fefc-458d-b294-c59d543f4321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
